{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7817b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEBUGGING DASHBOARD DATA LOADING\n",
      "============================================================\n",
      "\n",
      "1. Loading files...\n",
      "✅ forecast_data.pq: 471,731 rows\n",
      "✅ ensemble_forecasts.pq: 68,698 rows\n",
      "\n",
      "2. Column comparison:\n",
      "\n",
      "Forecast data columns:\n",
      "['reference_date', 'target', 'horizon', 'target_end_date', 'location', 'output_type', 'output_type_id', 'value', 'model']\n",
      "\n",
      "Ensemble data columns:\n",
      "['reference_date', 'location', 'horizon', 'target', 'target_end_date', 'output_type', 'output_type_id', 'value', 'model']\n",
      "\n",
      "3. Checking key columns:\n",
      "✅ reference_date: forecast=True, ensemble=True\n",
      "✅ target_end_date: forecast=True, ensemble=True\n",
      "✅ location: forecast=True, ensemble=True\n",
      "✅ horizon: forecast=True, ensemble=True\n",
      "✅ target: forecast=True, ensemble=True\n",
      "✅ output_type: forecast=True, ensemble=True\n",
      "✅ output_type_id: forecast=True, ensemble=True\n",
      "✅ value: forecast=True, ensemble=True\n",
      "\n",
      "4. Model column check:\n",
      "✅ forecast_data has 'model' column\n",
      "   Models: ['CEPH-Rtrend_fluH', 'Gatech-ensemble_prob', 'Gatech-ensemble_stat', 'MIGHTE-Joint', 'MIGHTE-Nsemble']...\n",
      "✅ ensemble_data has 'model' column\n",
      "   Models: ['Median_Ensemble' 'Median Epistorm Ensemble']\n",
      "\n",
      "5. Data type comparison:\n",
      "✅ reference_date: forecast=datetime64[ns], ensemble=datetime64[ns]\n",
      "✅ target_end_date: forecast=datetime64[ns], ensemble=datetime64[ns]\n",
      "✅ location: forecast=object, ensemble=object\n",
      "✅ horizon: forecast=int64, ensemble=int64\n",
      "✅ target: forecast=object, ensemble=object\n",
      "✅ output_type: forecast=object, ensemble=object\n",
      "✅ output_type_id: forecast=object, ensemble=object\n",
      "✅ value: forecast=float64, ensemble=float64\n",
      "\n",
      "6. Sample data:\n",
      "\n",
      "Forecast data sample:\n",
      "  reference_date           target  horizon target_end_date location  \\\n",
      "0     2025-11-22  wk inc flu hosp        0      2025-11-22       01   \n",
      "1     2025-11-22  wk inc flu hosp        0      2025-11-22       01   \n",
      "\n",
      "  output_type output_type_id     value           model  \n",
      "0    quantile           0.01  5.227068  MIGHTE-Nsemble  \n",
      "1    quantile          0.025  6.689334  MIGHTE-Nsemble  \n",
      "\n",
      "Ensemble data sample:\n",
      "  reference_date location  horizon           target target_end_date  \\\n",
      "0     2025-11-22       01        0  wk inc flu hosp      2025-11-22   \n",
      "1     2025-11-22       01        0  wk inc flu hosp      2025-11-22   \n",
      "\n",
      "  output_type output_type_id  value            model  \n",
      "0    quantile           0.01    9.0  Median_Ensemble  \n",
      "1    quantile          0.025   11.0  Median_Ensemble  \n",
      "\n",
      "7. Testing combine:\n",
      "✅ Successfully combined: 540,429 rows\n",
      "   Models: 12\n",
      "   Median_Ensemble present: ✅\n",
      "   Median_Ensemble rows: 58,098\n",
      "   Targets: ['wk inc flu hosp']\n",
      "   Output types: ['quantile']\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Debug script to compare ensemble files with dashboard expectations\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DEBUGGING DASHBOARD DATA LOADING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load all the data\n",
    "print(\"\\n1. Loading files...\")\n",
    "try:\n",
    "    forecast_data = pd.read_parquet('data/all_forecasts.parquet')\n",
    "    print(f\"✅ forecast_data.pq: {len(forecast_data):,} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading forecast_data.pq: {e}\")\n",
    "    forecast_data = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    ensemble_data = pd.read_parquet('data/ensemble_forecasts.pq')\n",
    "    print(f\"✅ ensemble_forecasts.pq: {len(ensemble_data):,} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading ensemble_forecasts.pq: {e}\")\n",
    "    ensemble_data = pd.DataFrame()\n",
    "\n",
    "# Compare column names\n",
    "print(\"\\n2. Column comparison:\")\n",
    "print(\"\\nForecast data columns:\")\n",
    "print(forecast_data.columns.tolist())\n",
    "\n",
    "print(\"\\nEnsemble data columns:\")\n",
    "print(ensemble_data.columns.tolist())\n",
    "\n",
    "# Check for mismatches\n",
    "forecast_cols = set(forecast_data.columns)\n",
    "ensemble_cols = set(ensemble_data.columns)\n",
    "\n",
    "missing_in_ensemble = forecast_cols - ensemble_cols\n",
    "extra_in_ensemble = ensemble_cols - forecast_cols\n",
    "\n",
    "if missing_in_ensemble:\n",
    "    print(f\"\\n⚠️ Columns in forecast but NOT in ensemble: {missing_in_ensemble}\")\n",
    "if extra_in_ensemble:\n",
    "    print(f\"\\n⚠️ Columns in ensemble but NOT in forecast: {extra_in_ensemble}\")\n",
    "\n",
    "# Check key columns exist\n",
    "print(\"\\n3. Checking key columns:\")\n",
    "required_cols = ['reference_date', 'target_end_date', 'location', 'horizon', \n",
    "                 'target', 'output_type', 'output_type_id', 'value']\n",
    "\n",
    "for col in required_cols:\n",
    "    in_forecast = col in forecast_data.columns\n",
    "    in_ensemble = col in ensemble_data.columns\n",
    "    status = \"✅\" if (in_forecast and in_ensemble) else \"❌\"\n",
    "    print(f\"{status} {col}: forecast={in_forecast}, ensemble={in_ensemble}\")\n",
    "\n",
    "# Check model column (could be 'model' or 'Model')\n",
    "print(\"\\n4. Model column check:\")\n",
    "if 'model' in forecast_data.columns:\n",
    "    print(f\"✅ forecast_data has 'model' column\")\n",
    "    print(f\"   Models: {sorted(forecast_data['model'].unique())[:5]}...\")\n",
    "elif 'Model' in forecast_data.columns:\n",
    "    print(f\"✅ forecast_data has 'Model' column (capital M)\")\n",
    "    print(f\"   Models: {sorted(forecast_data['Model'].unique())[:5]}...\")\n",
    "else:\n",
    "    print(f\"❌ forecast_data has NO model column!\")\n",
    "\n",
    "if 'model' in ensemble_data.columns:\n",
    "    print(f\"✅ ensemble_data has 'model' column\")\n",
    "    print(f\"   Models: {ensemble_data['model'].unique()}\")\n",
    "elif 'Model' in ensemble_data.columns:\n",
    "    print(f\"✅ ensemble_data has 'Model' column (capital M)\")\n",
    "    print(f\"   Models: {ensemble_data['Model'].unique()}\")\n",
    "else:\n",
    "    print(f\"❌ ensemble_data has NO model column!\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n5. Data type comparison:\")\n",
    "for col in required_cols:\n",
    "    if col in forecast_data.columns and col in ensemble_data.columns:\n",
    "        forecast_dtype = forecast_data[col].dtype\n",
    "        ensemble_dtype = ensemble_data[col].dtype\n",
    "        match = \"✅\" if forecast_dtype == ensemble_dtype else \"⚠️\"\n",
    "        print(f\"{match} {col}: forecast={forecast_dtype}, ensemble={ensemble_dtype}\")\n",
    "\n",
    "# Check sample values\n",
    "print(\"\\n6. Sample data:\")\n",
    "print(\"\\nForecast data sample:\")\n",
    "print(forecast_data.head(2))\n",
    "\n",
    "print(\"\\nEnsemble data sample:\")\n",
    "print(ensemble_data.head(2))\n",
    "\n",
    "# Try combining them\n",
    "print(\"\\n7. Testing combine:\")\n",
    "try:\n",
    "    # Standardize model column\n",
    "    if 'Model' in ensemble_data.columns and 'model' not in ensemble_data.columns:\n",
    "        ensemble_data['model'] = ensemble_data['Model']\n",
    "        ensemble_data = ensemble_data.drop(columns=['Model'])\n",
    "    \n",
    "    combined = pd.concat([forecast_data, ensemble_data], ignore_index=True)\n",
    "    print(f\"✅ Successfully combined: {len(combined):,} rows\")\n",
    "    print(f\"   Models: {combined['model'].nunique() if 'model' in combined.columns else 'N/A'}\")\n",
    "    \n",
    "    # Check if Median_Ensemble is there\n",
    "    if 'model' in combined.columns:\n",
    "        has_ensemble = 'Median_Ensemble' in combined['model'].values\n",
    "        print(f\"   Median_Ensemble present: {'✅' if has_ensemble else '❌'}\")\n",
    "        \n",
    "        if has_ensemble:\n",
    "            ensemble_subset = combined[combined['model'] == 'Median_Ensemble']\n",
    "            print(f\"   Median_Ensemble rows: {len(ensemble_subset):,}\")\n",
    "            print(f\"   Targets: {ensemble_subset['target'].unique()}\")\n",
    "            print(f\"   Output types: {ensemble_subset['output_type'].unique()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error combining: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8310e603",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tc/9lbjwrhx1dv0_0vb1_v_4q6r0000gp/T/ipykernel_68554/54590677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check date formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: reference_date dtype:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reference_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DEBUG: target_end_date dtype:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_end_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "# Check date formats\n",
    "st.write(\"DEBUG: reference_date dtype:\", forecast_data['reference_date'].dtype)\n",
    "st.write(\"DEBUG: target_end_date dtype:\", forecast_data['target_end_date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b40d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
